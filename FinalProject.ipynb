{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c2af9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import corpus\n",
    "from nltk import tokenize\n",
    "cv=CountVectorizer()\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "073f89b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeah I got 2 backups for all that. I just hate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate using my BB  but love my iPhone. Haven'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  label\n",
       "0  yeah I got 2 backups for all that. I just hate...      0\n",
       "1  I hate using my BB  but love my iPhone. Haven'...      0\n",
       "2                             Get fucking real dude.      1\n",
       "3   She is as dirty as they come  and that crook ...      1\n",
       "4   why did you fuck it up. I could do it all day...      1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('new_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b290013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0007aeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8817, 2)\n"
     ]
    }
   ],
   "source": [
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "944a7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataType=df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84dd565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments    object\n",
      "label        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(DataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e547158",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73151208",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fee9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       yeah I got 2 backups for all that. I just hate...\n",
      "1       I hate using my BB  but love my iPhone. Haven'...\n",
      "2                                  Get fucking real dude.\n",
      "3        She is as dirty as they come  and that crook ...\n",
      "4        why did you fuck it up. I could do it all day...\n",
      "                              ...                        \n",
      "8812    no caffiene would kick my ass too - I'm addict...\n",
      "8813    Now I'm hungry.  Damn you people and your midn...\n",
      "8814    i've taken one also. people just piss me off m...\n",
      "8815    That  too! Or even being able to park pulling ...\n",
      "8816                          . . . HE'S FUCKING HIMSELF!\n",
      "Name: comments, Length: 8817, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#output the  comments \n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db3e22aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "8812    0\n",
      "8813    0\n",
      "8814    0\n",
      "8815    0\n",
      "8816    1\n",
      "Name: label, Length: 8817, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e119573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8817,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce206586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8817,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2049d481",
   "metadata": {},
   "source": [
    "# Data cleaning using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e4cc9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    yeah I got 2 backups for all that I just hate ...\n",
       "1    I hate using my BB  but love my iPhone Havent ...\n",
       "2                                Get fucking real dude\n",
       "3     She is as dirty as they come  and that crook ...\n",
       "4     why did you fuck it up I could do it all day ...\n",
       "5     Dude they dont finish enclosing the fucking s...\n",
       "6     WTF are you talking about Men No men thats no...\n",
       "7    Ill save you the trouble sister Here comes a b...\n",
       "8     Im dead seriousReal athletes never cheat dont...\n",
       "9        wow lol sounds like a lot of piss then hehehe\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing punctuation\n",
    "def remove_punctuation(text):\n",
    "    no_punct=\"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "import pandas as pd\n",
    "df=pd.read_csv('new_data.csv')\n",
    "df['comments'] = df['comments'].apply(lambda x: remove_punctuation(x))\n",
    "df['comments'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4bf1fac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [yeah, i, got, 2, backups, for, all, that, i, ...\n",
       "1     [i, hate, using, my, bb, but, love, my, iphone...\n",
       "2                            [get, fucking, real, dude]\n",
       "3     [she, is, as, dirty, as, they, come, and, that...\n",
       "4     [why, did, you, fuck, it, up, i, could, do, it...\n",
       "5     [dude, they, dont, finish, enclosing, the, fuc...\n",
       "6     [wtf, are, you, talking, about, men, no, men, ...\n",
       "7     [ill, save, you, the, trouble, sister, here, c...\n",
       "8     [im, dead, serious, real, athletes, never, che...\n",
       "9     [wow, lol, sounds, like, a, lot, of, piss, the...\n",
       "10    [not, a, damn, thang, the, typical, rap, beef,...\n",
       "11    [go, absolutely, insane, hate, to, be, the, be...\n",
       "12    [well, damn, where, have, you, been, when, i, ...\n",
       "13    [watching, without, a, trace, too, hate, when,...\n",
       "14    [which, they, do, most, of, the, time, p, i, d...\n",
       "15    [lmao, im, watching, the, same, thing, ahaha, ...\n",
       "16    [lol, no, he, said, what, do, you, call, a, ja...\n",
       "17    [truth, on, both, counts, that, guy, is, an, a...\n",
       "18                                  [shakespeare, nerd]\n",
       "19                   [you, are, such, a, fucking, dork]\n",
       "Name: comments, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizing\n",
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "df=pd.read_csv('new_data.csv')\n",
    "df.head()\n",
    "\n",
    "df['comments'] = df['comments'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df['comments'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acd59213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STOP WORDS\n",
    "stopwords=nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffe70826",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9704\\4108563447.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfile1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    file1 = codecs.open('new_data.csv','r','utf-8') \n",
    "    line = file1.read() \n",
    "    words = line.split()\n",
    "    for r in words: \n",
    "        if not r in stop_words: \n",
    "            appendFile = open('stopwords.csv','a', encoding='utf-8') \n",
    "            appendFile.write(\" \"+r)\n",
    "            appendFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54348bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
